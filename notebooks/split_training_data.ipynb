{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training Data\n",
    "\n",
    "Analyze filtered fragments and split into train/validation/test sets (80/10/10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports loaded\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config import PROCESSED_DATA_DIR\n",
    "\n",
    "print(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Filtered Fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filtered fragments\n",
    "fragments_path = PROCESSED_DATA_DIR / \"ao3_fragments_selfcontained.csv\"\n",
    "df = pd.read_csv(fragments_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data (80/10/10)\n",
    "\n",
    "Split into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fragments: 133,043\n",
      "\n",
      "Train: 106,434 (80.0%)\n",
      "Validation: 13,304 (10.0%)\n",
      "Test: 13,305 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# First split: 80% train, 20% temp\n",
    "train_df, valtest_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: split temp into 50/50 for val and test (10% each of original)\n",
    "val_df, test_df = train_test_split(valtest_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Total fragments: {len(df):,}\")\n",
    "print(f\"\\nTrain: {len(train_df):,} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation: {len(val_df):,} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test: {len(test_df):,} ({len(test_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format for Training (JSONL)\n",
    "\n",
    "Convert to simple JSONL format with just the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_jsonl(df, path):\n",
    "    \"\"\"Save dataframe as JSONL with just text field\"\"\"\n",
    "    with open(path, 'w') as f:\n",
    "        for text in df['text']:\n",
    "            f.write(json.dumps({\"text\": text}) + '\\n')\n",
    "    print(f\"Saved {len(df):,} examples to {path}\")\n",
    "\n",
    "# Save splits\n",
    "train_path = PROCESSED_DATA_DIR / \"train.jsonl\"\n",
    "val_path = PROCESSED_DATA_DIR / \"val.jsonl\"\n",
    "test_path = PROCESSED_DATA_DIR / \"test.jsonl\"\n",
    "\n",
    "save_jsonl(train_df, train_path)\n",
    "save_jsonl(val_df, val_path)\n",
    "save_jsonl(test_df, test_path)\n",
    "\n",
    "print(\"\\n✓ Data splits saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview train file\n",
    "print(\"First 5 lines of train.jsonl:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with open(train_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        print(f\"{i+1}. {data['text']}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
