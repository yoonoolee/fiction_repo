{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Prepare Training Data\n",
    "\n",
    "Creates 3 datasets with train/val/test splits (80/10/10):\n",
    "1. **Combined**: Balanced (10k one-liners + 10k short stories)\n",
    "2. **One-Liner**: Full dataset (~2k)\n",
    "3. **Short-Story**: Full dataset (~50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append('..')\n",
    "from config import PROCESSED_DATA_DIR\n",
    "\n",
    "TRAIN_DIR = Path(\"../data/train\")\n",
    "TRAIN_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51,337 rows\n"
     ]
    }
   ],
   "source": [
    "input_path = PROCESSED_DATA_DIR / \"ao3_tifu_enriched_labels_with_instruction.parquet\"\n",
    "df = pd.read_parquet(input_path)\n",
    "print(f\"Loaded {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced: 20,000 rows\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = 10000\n",
    "\n",
    "one_liner_df = df[df['type'] == 'one_liner'].copy()\n",
    "short_story_df = df[df['type'] == 'short_story'].copy()\n",
    "\n",
    "short_story_balanced = short_story_df.sample(n=TARGET_SIZE, random_state=42)\n",
    "one_liner_balanced = one_liner_df.sample(n=TARGET_SIZE, replace=True, random_state=42)\n",
    "\n",
    "balanced_df = pd.concat([one_liner_balanced, short_story_balanced], ignore_index=True)\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Balanced: {len(balanced_df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Create 3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = balanced_df.copy()\n",
    "one_liner_full_df = one_liner_df.copy()\n",
    "short_story_full_df = short_story_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Split into Train/Val/Test (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined: 15,999 train / 2,001 val / 2,000 test\n",
      "One-liner: 1,671 train / 210 val / 210 test\n",
      "Short-story: 39,396 train / 4,925 val / 4,925 test\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(df, test_size=0.1, val_size=0.1, random_state=42):\n",
    "    \"\"\"Split dataset into train/val/test (80/10/10).\"\"\"\n",
    "    train_val, test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    train, val = train_test_split(train_val, test_size=val_size/(1-test_size), random_state=random_state)\n",
    "    return train, val, test\n",
    "\n",
    "combined_train, combined_val, combined_test = split_dataset(combined_df)\n",
    "one_liner_train, one_liner_val, one_liner_test = split_dataset(one_liner_full_df)\n",
    "short_story_train, short_story_val, short_story_test = split_dataset(short_story_full_df)\n",
    "\n",
    "print(f\"Combined: {len(combined_train):,} train / {len(combined_val):,} val / {len(combined_test):,} test\")\n",
    "print(f\"One-liner: {len(one_liner_train):,} train / {len(one_liner_val):,} val / {len(one_liner_test):,} test\")\n",
    "print(f\"Short-story: {len(short_story_train):,} train / {len(short_story_val):,} val / {len(short_story_test):,} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Format for Instruction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_instruction_tuning(df):\n",
    "    \"\"\"Convert to instruction-tuning format.\"\"\"\n",
    "    formatted = []\n",
    "    for _, row in df.iterrows():\n",
    "        example = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": row['instruction']},\n",
    "                {\"role\": \"assistant\", \"content\": row['text']}\n",
    "            ]\n",
    "        }\n",
    "        formatted.append(example)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Save JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved 9 JSONL files to data/train/\n"
     ]
    }
   ],
   "source": [
    "def save_to_jsonl(data, filepath):\n",
    "    \"\"\"Save formatted data to JSONL.\"\"\"\n",
    "    with open(filepath, 'w') as f:\n",
    "        for example in data:\n",
    "            f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "# Combined\n",
    "save_to_jsonl(format_for_instruction_tuning(combined_train), TRAIN_DIR / \"combined_train.jsonl\")\n",
    "save_to_jsonl(format_for_instruction_tuning(combined_val), TRAIN_DIR / \"combined_val.jsonl\")\n",
    "save_to_jsonl(format_for_instruction_tuning(combined_test), TRAIN_DIR / \"combined_test.jsonl\")\n",
    "\n",
    "# One-liner\n",
    "save_to_jsonl(format_for_instruction_tuning(one_liner_train), TRAIN_DIR / \"one_liner_train.jsonl\")\n",
    "save_to_jsonl(format_for_instruction_tuning(one_liner_val), TRAIN_DIR / \"one_liner_val.jsonl\")\n",
    "save_to_jsonl(format_for_instruction_tuning(one_liner_test), TRAIN_DIR / \"one_liner_test.jsonl\")\n",
    "\n",
    "# Short-story\n",
    "save_to_jsonl(format_for_instruction_tuning(short_story_train), TRAIN_DIR / \"short_story_train.jsonl\")\n",
    "save_to_jsonl(format_for_instruction_tuning(short_story_val), TRAIN_DIR / \"short_story_val.jsonl\")\n",
    "save_to_jsonl(format_for_instruction_tuning(short_story_test), TRAIN_DIR / \"short_story_test.jsonl\")\n",
    "\n",
    "print(\"✓ Saved 9 JSONL files to data/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51643466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
